{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "['SW', 'SOLV', 'GEV', 'AMTM']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2023-01-01 -> 2024-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 1672549200, endDate = 1704085200\")')\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch S&P 500 data\n",
    "def get_sp500_tickers():\n",
    "    # Get S&P 500 tickers from Wikipedia\n",
    "    sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    table = pd.read_html(sp500_url, header=0)\n",
    "    tickers = table[0]['Symbol'].tolist()\n",
    "    return tickers\n",
    "\n",
    "# Fetch S&P 500 tickers\n",
    "tickers = get_sp500_tickers()\n",
    "tickers = [ticker.replace('.', '-') for ticker in tickers]  # Adjust for yfinance\n",
    "\n",
    "# Download historical data for the last year\n",
    "data = yf.download(tickers, start=\"2023-01-01\", end=\"2024-01-01\")['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocessing - Remove Excessive Missing Values\n",
    "data_rem = data.dropna(thresh=int(0.8 * len(data.columns)), axis=0)  # At least 80% valid rows\n",
    "data_rem = data_rem.dropna(thresh=int(0.8 * len(data)), axis=1)  # At least 80% valid columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 stocks by weight in the dominant principal component:\n",
      "    Stock    Weight\n",
      "263   KEY  0.110713\n",
      "124   CZR  0.104890\n",
      "372  PLTR  0.098506\n",
      "161  ENPH  0.096758\n",
      "357  PARA  0.096528\n",
      "207  GNRC  0.093151\n",
      "477   WBD  0.091262\n",
      "81    CCL  0.090935\n",
      "87    CFG  0.087999\n",
      "71    BXP  0.087628\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Calculate centered log returns\n",
    "centered_log_returns = log_returns - log_returns.mean()\n",
    "\n",
    "# Step 4: Compute covariance matrix of centered log returns\n",
    "cov_matrix = centered_log_returns.cov()\n",
    "\n",
    "# Step 5: Perform spectral decomposition\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Dominant principal component\n",
    "dominant_pc = eigenvectors[:, 0]\n",
    "\n",
    "# Ensure positive orientation of the dominant PC\n",
    "if dominant_pc[0] < 0:\n",
    "    dominant_pc *= -1\n",
    "\n",
    "# Create DataFrame for stock weights\n",
    "stock_weights = pd.DataFrame({\n",
    "    'Stock': centered_log_returns.columns,\n",
    "    'Weight': dominant_pc\n",
    "}).sort_values(by='Weight', ascending=False)\n",
    "\n",
    "# Output\n",
    "print(\"Top 10 stocks by weight in the dominant principal component:\")\n",
    "print(stock_weights.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
